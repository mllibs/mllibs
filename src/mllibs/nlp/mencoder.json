{
  "modules": [
    
    {
      "name": "encoding_ohe",
    "corpus": [
              "one hot encode",
              "one-hot-encode",
              "ohe",
              "one-hot encode",
              "encode with one-hot-encoding",
              "encoded with ohe"
              ],
      "info": {
              "module":"encoder",
              "action":"create encoding",
              "topic":"natural language processing",
              "subtopic":"create features",
              "input_format":"pd.DataFrame",
              "output":"data",
              "description":"create numerical represention of feature columns containing string names",
              "token_compat":"data subset",
               "arg_compat":"None"
              }
    },

    {
      "name": "encoding_label",
    "corpus": [
              "label encode",
              "encode label",
              "label encoder",
              "encode target variable",
              "label encode taget variable",
              "LabelEncoder"
              ],
      "info": {
              "module":"encoder",
              "action":"create encoding",
              "topic":"natural language processing",
              "subtopic":"label encoding",
              "input_format":"pd.DataFrame",
              "output": "data vectoriser",
              "description":"create numerical presentation of target label containing string names",
              "token_compat":"data subset",
              "arg_compat":"None"
              }
    },

    {
      "name": "count_vectoriser",
    "corpus": [
              "count vectorise",
              "count vectoriser",
              "make bag of words",
              "create bag of words",
              "bow vectorisation",
              "CountVectorizer"
              ],
      "info": {
              "module":"encoder",
              "action":"create encoding",
              "topic":"natural language processing",
              "subtopic":"feature generation",
              "input_format":"pd.DataFrame",
              "output": "data vectoriser",
              "description":"Convert a collection of text documents to a matrix of token counts (unigrams)",
              "token_compat":"data subset",
              "arg_compat":"ngram_range min_df max_df tokeniser"
              }
    },

    {
      "name": "tfidf_vectoriser",
    "corpus": [
              "tfidf vectorise",
              "tfidf vectorisation",
              "tfidf",
              "vectorisation using tfidf",
              "TfidfVectorizer"
              ],
      "info": {
              "module":"encoder",
              "action":"create encoding",
              "topic":"natural language processing",
              "subtopic":"feature generation",
              "input_format":"pd.DataFrame",
              "output": "data vectoriser",
              "description":"Convert a collection of raw documents to a matrix of TF-IDF features",
              "token_compat":"data subset",
              "arg_compat":"ngram_range min_df max_df use_idf smooth_idf tokeniser"
              }
    },

    {
      "name": "torch_text_encode",
    "corpus": [
              "encode documents into tensor",
              "encode document into tensor",
              "encode corpus into tensor",
              "torch encode documents",
              "encode documents for torch",
              "encode document for torch",
              "encode corpus for torch",
              "encode text corpus for torch",
              "encode document corpus for torch",
              "encode text corpus for torch"
              ],
      "info": {
              "module":"encoder",
              "action":"create encoding",
              "topic":"natural language processing",
              "subtopic":"feature generation",
              "input_format":"list",
              "output":"data",
              "description":"Encode documents into numeric representation & add padding to create tensor of identical length",
              "token_compat":"data",
              "arg_compat": "maxlen"
              }
    }

  ]
}