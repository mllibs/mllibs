{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c991d33-26f6-40a1-9365-f4bda2437d07",
   "metadata": {},
   "source": [
    "## **Named Entity Recognition** \n",
    "\n",
    "### **NER Parser**\n",
    "\n",
    "Create NER tagger to identify words/tokens of interest in input request, it is used to set parameters & remove irrelovant tokens before feeding the input into the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e4131af7-ea30-466c-895e-10ce258e967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import regex as re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "'''\n",
    "\n",
    "PARSER FOR THE DATASET NER TAG FORMAT\n",
    "\n",
    "'''\n",
    "\n",
    "class Parser:\n",
    "    \n",
    "    # RE patterns for tag extraction\n",
    "    LABEL_PATTERN = r\"\\[(.*?)\\]\"\n",
    "    PUNCTUATION_PATTERN = r\"([,\\/#!$%\\^&\\*;:{}=\\-`~()'\\\"’¿])\"\n",
    "    \n",
    "    \n",
    "    # initialise, first word/id tag is O (outside)\n",
    "    def __init__(self):\n",
    "        self.tag_to_id = {\n",
    "            \"O\": 0\n",
    "        }\n",
    "        self.id_to_tag = {\n",
    "            0: \"O\"\n",
    "        }\n",
    "        \n",
    "    ''' CREATE TAGS '''\n",
    "        \n",
    "    # input : sentence, tagged sentence\n",
    "        \n",
    "    def __call__(self, sentence: str, annotated: str) -> List[str]:\n",
    "        \n",
    "        ''' Create Dictionary of Identified Tags'''\n",
    "        \n",
    "        # 1. set label B or I    \n",
    "        matches = re.findall(self.LABEL_PATTERN, annotated)\n",
    "        word_to_tag = {}\n",
    "        \n",
    "        for match in matches:            \n",
    "            if(\" : \" in match):\n",
    "                tag, phrase = match.split(\" : \")\n",
    "                words = phrase.split(\" \") \n",
    "                word_to_tag[words[0]] = f\"B-{tag.upper()}\"\n",
    "                for w in words[1:]:\n",
    "                    word_to_tag[w] = f\"I-{tag.upper()}\"\n",
    "                \n",
    "        ''' Tokenise Sentence & add tags to not tagged words (O)'''\n",
    "                \n",
    "        # 2. add token tag to main tag dictionary\n",
    "\n",
    "        tags = []\n",
    "        sentence = re.sub(self.PUNCTUATION_PATTERN, r\" \\1 \", sentence)\n",
    "        \n",
    "        for w in sentence.split():\n",
    "            if w not in word_to_tag:\n",
    "                tags.append(\"O\")\n",
    "            else:\n",
    "                tags.append(word_to_tag[w])\n",
    "                self.__add_tag(word_to_tag[w])\n",
    "                \n",
    "        return tags\n",
    "    \n",
    "    ''' TAG CONVERSION '''\n",
    "    \n",
    "    # to word2id (tag_to_id)\n",
    "    # to id2word (id_to_tag)\n",
    "\n",
    "    def __add_tag(self, tag: str):\n",
    "        if tag in self.tag_to_id:\n",
    "            return\n",
    "        id_ = len(self.tag_to_id)\n",
    "        self.tag_to_id[tag] = id_\n",
    "        self.id_to_tag[id_] = tag\n",
    "        \n",
    "        ''' Get Tag Number ID '''\n",
    "        # or just number id for token\n",
    "        \n",
    "    def get_id(self, tag: str):\n",
    "        return self.tag_to_id[tag]\n",
    "    \n",
    "    ''' Get Tag Token from Number ID'''\n",
    "    # given id get its token\n",
    "    \n",
    "    def get_label(self, id_: int):\n",
    "        return self.get_tag_label(id_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "55ee2548-9dda-493a-bdd5-89cd0aa8947a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/miniconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-PARAM       0.99      1.00      0.99        80\n",
      "        B-PP       1.00      1.00      1.00         9\n",
      "    B-SOURCE       0.76      1.00      0.87        52\n",
      "    B-SUBSET       1.00      0.08      0.14        13\n",
      "    I-SOURCE       0.94      1.00      0.97        16\n",
      "    I-SUBSET       0.70      1.00      0.82        16\n",
      "           O       1.00      0.96      0.98       322\n",
      "\n",
      "    accuracy                           0.95       508\n",
      "   macro avg       0.91      0.86      0.82       508\n",
      "weighted avg       0.96      0.95      0.94       508\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B-PARAM</th>\n",
       "      <th>B-PP</th>\n",
       "      <th>B-SOURCE</th>\n",
       "      <th>B-SUBSET</th>\n",
       "      <th>I-SOURCE</th>\n",
       "      <th>I-SUBSET</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-PARAM</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PP</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-SOURCE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-SUBSET</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-SOURCE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-SUBSET</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          B-PARAM  B-PP  B-SOURCE  B-SUBSET  I-SOURCE  I-SUBSET    O\n",
       "B-PARAM        80     0         0         0         0         0    0\n",
       "B-PP            0     9         0         0         0         0    0\n",
       "B-SOURCE        0     0        52         0         0         0    0\n",
       "B-SUBSET        0     0        10         1         0         2    0\n",
       "I-SOURCE        0     0         0         0        16         0    0\n",
       "I-SUBSET        0     0         0         0         0        16    0\n",
       "O               1     0         6         0         1         5  309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "NER with Machine Learning Models\n",
    "\n",
    "'''\n",
    "    \n",
    "# pattern for tokenisation\n",
    "PUNCTUATION_PATTERN = r\"([,\\/#!$%\\^&\\*;:{}=\\-`~()'\\\"’¿])\"\n",
    "\n",
    "# customiser tokeniser\n",
    "def cust_tokeniser(inputs):\n",
    "    sentence = re.sub(PUNCTUATION_PATTERN, r\" \\1 \", inputs)\n",
    "    return sentence.split()\n",
    "\n",
    "# parser\n",
    "parser = Parser()\n",
    "df = pd.read_csv('ner_modelparams_annot.csv')   # read dataframe\n",
    "\n",
    "def make_model(parser,df):\n",
    "\n",
    "    # parse our NER tag data & tokenise our text\n",
    "    lst_data = []; lst_tags = []\n",
    "    for ii,row in df.iterrows():\n",
    "        sentence = re.sub(PUNCTUATION_PATTERN, r\" \\1 \", row['text'])\n",
    "        lst_data.extend(sentence.split())\n",
    "        lst_tags.extend(parser(row[\"text\"], row[\"annot\"]))\n",
    "    \n",
    "    ldf = pd.DataFrame({'data':lst_data,\n",
    "                        'tag':lst_tags})\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    Vectorisation \n",
    "    \n",
    "    '''\n",
    "        \n",
    "    # define encoder\n",
    "    # encoder = CountVectorizer(tokenizer=cust_tokeniser,ngram_range=(1,1))\n",
    "    encoder = CountVectorizer(tokenizer=cust_tokeniser)\n",
    "    # encoder = TfidfVectorizer(tokenizer=cust_tokeniser,ngram_range=(1,5))\n",
    "    X = encoder.fit_transform(lst_data)\n",
    "    y = np.array(lst_tags)\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    Modeling \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # try our different models\n",
    "    # model_confirm = LogisticRegression()\n",
    "    model_confirm = RandomForestClassifier(max_depth=200,min_samples_split=10)\n",
    "    \n",
    "    # train model\n",
    "    model_confirm.fit(X,y)\n",
    "    y_pred = model_confirm.predict(X)\n",
    "    print(f'accuracy: {round(accuracy_score(y_pred,y),3)}')\n",
    "\n",
    "    print(classification_report(y, y_pred))\n",
    "    display(pd.DataFrame(confusion_matrix(y,y_pred),index=model_confirm.classes_,columns=model_confirm.classes_))\n",
    "    return model_confirm,encoder\n",
    "\n",
    "model,encoder = make_model(parser,df)\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2843ea96-4a0b-4693-9f00-ab3df268b066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>create</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>label</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>encoding</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>using</td>\n",
       "      <td>B-SOURCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data</td>\n",
       "      <td>I-SOURCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>subset</td>\n",
       "      <td>B-SUBSET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      input      pred\n",
       "0    create         O\n",
       "1     label         O\n",
       "2  encoding         O\n",
       "3     using  B-SOURCE\n",
       "4      data  I-SOURCE\n",
       "5         E         O\n",
       "6       and         O\n",
       "7    subset  B-SUBSET\n",
       "8         B         O"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = \"create scatterplot using data and x A y B and hue C\"\n",
    "# inputs = \"create relplot using data x flow, y length col:A and row D, alpha 0.1\"\n",
    "# inputs1 = \"create seaborn scatterplot using data penguins x bill_length_mm y bill_depth_mm hue island\"\n",
    "# inputs2 = \"create seaborn scatterplot using penguins x bill_length_mm y bill_depth_mm hue island\"\n",
    "# inputs = \"create seaborn scatterplot using data penguins x bill_length_mm y bill_depth_mm hue island select numerical features only\"\n",
    "# inputs = \"create seaborn scatterplot using data penguins (use numerical columns only) x bill_length_mm y bill_depth_mm hue island\"\n",
    "\n",
    "'''\n",
    "\n",
    "Implementing references to dataframe subsets\n",
    "\n",
    "'''\n",
    "\n",
    "# inputs = \"create label encoding of column B using data A\"     # not ok\n",
    "# inputs = \"create label encoding for column B using data A\"    # not ok\n",
    "# inputs = \"create one hot encoding of columns A B C using data E\" # ok\n",
    "# inputs = \"create label encoding using active columns C from data E\"\n",
    "inputs = \"create label encoding using data E and subset B\"\n",
    "\n",
    "# predict NER tags\n",
    "def ner_predict(inputs):\n",
    "    # tokens = word_tokenize(inputs)\n",
    "    tokens = cust_tokeniser(inputs)\n",
    "    y_pred_test = model.predict(encoder.transform(tokens))\n",
    "\n",
    "    return pd.DataFrame({\"input\":tokens,\n",
    "                         \"pred\":y_pred_test})\n",
    "\n",
    "\n",
    "outputs = ner_predict(inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "61c429af-b33a-443a-8888-f1edb77991b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "and\n"
     ]
    }
   ],
   "source": [
    "outputs = ner_predict(inputs)\n",
    "outputs\n",
    "\n",
    "tag_index = list(outputs[outputs['pred'].shift(0) == 'B-SOURCE'].index)\n",
    "\n",
    "matches = []\n",
    "for i in range(0,len(tag_index)):\n",
    "    matches.append(outputs.iloc[tag_index[i]:tag_index[i]+5])\n",
    "\n",
    "for match in matches:\n",
    "    for idx,row in match.iterrows():\n",
    "        \n",
    "        if(row['pred'] == 'O'):\n",
    "            print(row['input'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0c3f5cdd-ef27-4387-8d65-3dd2b33a1e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [1,2,3,4,5]\n",
    "my_list[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b06858c0-6ea5-4e12-b756-8e94f449ad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "my_list.reverse()\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1d5fb769-c586-482d-8da5-e1fefff8762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fedcba\n"
     ]
    }
   ],
   "source": [
    "str = 'abcdef'\n",
    "print(str[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8b9b50a7-1317-4ecd-9715-05bf9afbe18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0   1  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1   2  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2   3  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3   4  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4   5  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "3          NaN     NaN  2007  \n",
       "4       3450.0  female  2007  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import os; os.listdir('../../penguins.csv')\n",
    "\n",
    "df = pd.read_csv('../../penguins.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7721354d-5694-44e5-bf88-1286cef30013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.1</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.5</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.3</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.7</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>36.6</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>37.8</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>41.5</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bill_length_mm species\n",
       "0              39.1  Adelie\n",
       "1              39.5  Adelie\n",
       "2              40.3  Adelie\n",
       "3               NaN  Adelie\n",
       "4              36.7  Adelie\n",
       "..              ...     ...\n",
       "147            36.6  Adelie\n",
       "148            36.0  Adelie\n",
       "149            37.8  Adelie\n",
       "150            36.0  Adelie\n",
       "151            41.5  Adelie\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf = df[['bill_length_mm','species']]\n",
    "ldf.query(\"species == 'Adelie'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc70561-2447-45bb-932c-1ab32d38087c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
