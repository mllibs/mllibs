{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a78c6c5d-28eb-4f72-8801-0cb52b132e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "'''\n",
    "\n",
    "NER Annotation Class\n",
    "\n",
    "'''\n",
    "# import os\n",
    "# print(os.listdir())\n",
    "\n",
    "class ner_annotator:\n",
    "\t\n",
    "\tdef __init__(self,df:pd.DataFrame):\n",
    "\t\tself.df = df\n",
    "\t\tself.word2tag = {}\n",
    "\t\tself.LABEL_PATTERN = r\"\\[(.*?)\\]\"\n",
    "\t\tself.deactive_df = None\n",
    "\t\tself.active_df = None\n",
    "\t\t\n",
    "\t\tself.__initialise()\n",
    "\t\t\n",
    "\tdef __initialise(self):\n",
    "\t\t\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\t[1] ANNOTATION COLUMN RELATED OPERATIONS\n",
    "\t\t\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\t# if annotaion column is all empty\n",
    "\t\t\n",
    "\t\tif('annot' in self.df.columns):\n",
    "\t\t\t\n",
    "\t\t\tif(self.df['annot'].isna().sum() == self.df.shape[0]):\n",
    "\t\t\t\tself.df['annot'] = None\n",
    "\t\t\t\t\n",
    "\t\t\t# if annotation column is not empty\n",
    "\t\t\t\t\n",
    "\t\t\telif(self.df['annot'].isna().sum() != self.df.shape[0]):\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Store Tags\n",
    "\t\t\t\tfor idx,row_data in self.df.iterrows():\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# if its already been annotated\n",
    "\t\t\t\t\tif(type(row_data['annot']) == str):\n",
    "\t\t\t\t\t\tmatches = re.findall(self.LABEL_PATTERN, row_data['annot'] )\n",
    "\t\t\t\t\t\tfor match in matches:\n",
    "\t\t\t\t\t\t\tif(' : ' in match):\n",
    "\t\t\t\t\t\t\t\ttag, phrase = match.split(\" : \")\n",
    "\t\t\t\t\t\t\t\tself.word2tag[phrase] = tag\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t# if annotation column is not present\n",
    "\t\t\t\t\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tword2tag = {}\n",
    "\t\t\tself.df['annot'] = None    \n",
    "\t\t\t\n",
    "\t\t# active_df -> NaN are present\n",
    "\t\t# deactive_df -> already has annotations\n",
    "\t\t\t\n",
    "\t\tself.active_df = self.df[self.df['annot'].isna()]\n",
    "\t\tself.deactive_df = self.df[~self.df['annot'].isna()]\n",
    "\t\t\n",
    "\t'''\n",
    "\t\n",
    "\tREVIEW ANNOTATIONS\n",
    "\t\n",
    "\t'''\n",
    "\t# nullify rows which are not NaN, but don't have \n",
    "\t\t\n",
    "\tdef review_annotations(self):\n",
    "\t\tidx = list(self.deactive_df[~self.deactive_df[\"annot\"].str.contains(self.LABEL_PATTERN)]['annot'].index)\n",
    "\t\tannot = list(self.deactive_df[~self.deactive_df[\"annot\"].str.contains(self.LABEL_PATTERN)]['annot'].values)\n",
    "\t\t\n",
    "\t\tfor i,j in zip(idx,annot):\n",
    "\t\t\tprint(i,j)\n",
    "\t\t\t\n",
    "\t# drop annotations (from deactive_df)\n",
    "\t\t\t\n",
    "\tdef drop_annotations(self,idx:list):\n",
    "\t\tremove_df = self.deactive_df.iloc[idx]\n",
    "\t\tremove_df['annotated'] = None\n",
    "\t\tself.active_df = pd.concat([self.active_df,remove_df])\n",
    "\t\tself.deactive_df = self.deactive_df.drop(list(idx),axis=0)\n",
    "\t\tself.deactive_df.sort_index()\n",
    "\t\tprint('dopped annotations saving >> annot.csv')\n",
    "\t\tpd.to_csv('annot.csv',pd.concat([self.active_df,self.deactive_df]))\n",
    "\t\t\n",
    "\t'''\n",
    "\t\n",
    "\tANNOTATE ON ACTIVE ONLY\n",
    "\t\n",
    "\t'''\n",
    "\t\t\n",
    "\tdef ner_annotate(self):\n",
    "\t\t\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\tCycle through all rows\n",
    "\t\t\n",
    "\t\t'''\n",
    "\t\n",
    "\t\tfor idx,row_data in self.active_df.iterrows():\n",
    "\t\t\t\n",
    "\t\t\t# left hand side text data [text,annotation]\n",
    "\t\t\tq = row_data['text'] # question\n",
    "\t\t\tt = q                    # annotated [question holder]\n",
    "\t\t\t\n",
    "\t\t\t'''\n",
    "\t\t\t\n",
    "\t\t\tStart Annotating\n",
    "\t\t\t\n",
    "\t\t\t'''\n",
    "\t\t\t# q,t are not modified unless entered q\n",
    "\t\t\t\n",
    "\t\t\tannotate_row = True\n",
    "\t\t\twhile annotate_row is True:\n",
    "\t\t\t\t\n",
    "\t\t\t\tprint('Current Annotations:')\n",
    "\t\t\t\tprint(t,'\\n')\n",
    "\t\t\t\t\n",
    "\t\t\t\t# user input command (isn't modified)\n",
    "\t\t\t\tuser = input('tag (word-tag) format >> ')\n",
    "\t\t\t\t\n",
    "\t\t\t\t# [1] end of annotation (go to next row)\n",
    "\t\t\t\tif(user in ['quit','q']):\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t'''\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tQuit Annotating Current Row \n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t'''\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# [1] store annotation in dataframe\n",
    "\t\t\t\t\trow_data['annot'] = t\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# [2] store all found tags in dictionary (word2tag)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Store Tags (list of [X] matches]\n",
    "\t\t\t\t\tmatches = re.findall(self.LABEL_PATTERN, t)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# filter out incorrect matches\n",
    "\t\t\t\t\ttemp_matches = []\n",
    "\t\t\t\t\tfor match in matches:\n",
    "\t\t\t\t\t\tif(' : ' in match):\n",
    "\t\t\t\t\t\t\ttemp_matches.append(match)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\tmatches = temp_matches\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tfor match in matches:\n",
    "\t\t\t\t\t\ttag, phrase = match.split(\" : \")\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# if it hasn't already been added\n",
    "\t\t\t\t\t\tif(tag not in self.word2tag):\n",
    "\t\t\t\t\t\t\tself.word2tag[phrase] = tag\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# clean up output\n",
    "\t\t\t\t\t\t#               clear_output(wait=True)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# [2] stop annotation loop\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\tannotate_row = False\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\telif(user in 'stop'):\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t'''\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tStop Annotating \n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t'''\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tldf = pd.concat([self.deactive_df,self.active_df],axis=0)\n",
    "\t\t\t\t\tldf.to_csv('annot.csv',index=False)\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t# return\n",
    "\t\t\t\t\n",
    "\t\t\t\t# [3] Reset current Row Tags\n",
    "\t\t\t\t\n",
    "\t\t\t\telif(user in ['reset','r']):\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tt=q \n",
    "\t\t\t\t\tprint('[note] annotations have been reset!')\n",
    "\t\t\t\t\tprint(t,'\\n')\n",
    "\t\t\t\t\t\n",
    "#\t\t\t\t\tuser = input('tag (word-tag) format >> ')\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# [4] Show current \n",
    "\t\t\t\t\t\n",
    "\t\t\t\telif(user == 'show'):\n",
    "\t\t\t\t\tprint(self.word2tag)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\telif(user == 'dict'):\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tprint(self.word2tag)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# tags\n",
    "\t\t\t\t\ttokenised_t = word_tokenize(t)\n",
    "\t\t\t\t\tset_tokenised = set(tokenised_t)\n",
    "\t\t\t\t\tset_dict = set(self.word2tag.keys())\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tintersections = set_dict.intersection(set_tokenised) \n",
    "\t\t\t\t\tprint(intersections)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# list of input characters\n",
    "\t\t\t\t\tlst_t = list(t)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# for all found key intersections\n",
    "\t\t\t\t\tfor word in intersections:\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\ttag = self.word2tag[word]\n",
    "\t\t\t\t\t\texpress = f'[{tag} : {word}]'\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# function to remove cases found as part of word\n",
    "\t\t\t\t\t\tdef remove_wordmatches(inputs:str,match:str):\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\tindicies = [(m.start(),m.end()) for m in re.finditer(match,inputs)]\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\tindicies_filter = []\n",
    "\t\t\t\t\t\t\t# if character is to left and right a[found]b\n",
    "\t\t\t\t\t\t\tfor st_idx,end_idx in indicies:\n",
    "\t\t\t\t\t\t\t\tif(inputs[st_idx-1] == \" \" and inputs[end_idx] == \" \"):\n",
    "\t\t\t\t\t\t\t\t\tindicies_filter.append((st_idx,end_idx))\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\treturn indicies_filter\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# filter out cases w/ idx-1 -> string\n",
    "\t\t\t\t\t\tmatches = remove_wordmatches(t,word)\n",
    "\t\t\t\t\t\tprint('matches',matches)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# go through all found cases\n",
    "\t\t\t\t\t\tfor match in matches:\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\tlst_temp = lst_t # temp list\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t# get matching idx in list\n",
    "\t\t\t\t\t\t\tmatch_idxs = list(range(match[0],match[1]+1))\n",
    "\t\t\t\t\t\t\tword_len = match[1] - match[0]\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\tremove_ids = match_idxs.copy()\n",
    "\t\t\t\t\t\t\tremove_ids.pop(0)\n",
    "\t\t\t\t\t\t\tdel lst_temp[remove_ids[0]:remove_ids[-1]]\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t# replace annotation @ first mached index\n",
    "\t\t\t\t\t\t\tlst_temp[match[0]] = express\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\t# join everything back (t is updated)\n",
    "\t\t\t\t\t\tt = \"\".join(lst_t)\n",
    "\n",
    "\t\t\t\telif('-' in user):\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# parse input\n",
    "\t\t\t\t\tword,tag = user.split('-')\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif(word == ''):\n",
    "\t\t\t\t\t\tword = input('please add word >> ')\n",
    "\t\t\t\t\tif(tag == ''):\n",
    "\t\t\t\t\t\ttag = input('please add tag >> ')\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\tif(word in t):\n",
    "\t\t\t\t\t\texpress = f'[{tag} : {word}]' \n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t# function to remove cases found as part of word\n",
    "\t\t\t\t\tdef remove_wordmatches(inputs:str,match:str):\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tinputs = inputs + \" \"\n",
    "\t\t\t\t\t\tindicies = [(m.start(),m.end()) for m in re.finditer(match,inputs)]\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tindicies_filter = []\n",
    "                        \n",
    "\t\t\t\t\t\t# if character is to left and right a[found]b\n",
    "\t\t\t\t\t\tfor st_idx,end_idx in indicies:\n",
    "\t\t\t\t\t\t\tif(inputs[st_idx-1] == \" \" and inputs[end_idx] == \" \"):\n",
    "\t\t\t\t\t\t\t\tindicies_filter.append((st_idx,end_idx))\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\treturn indicies_filter\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t# filter out cases w/ idx-1 -> string\n",
    "\t\t\t\t\tmatches = remove_wordmatches(t,word)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# change string to list\n",
    "\t\t\t\t\tlst_temp = list(t)\n",
    "\n",
    "\t\t\t\t\t# go through all found cases\n",
    "\t\t\t\t\tfor match in matches:\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# get matching idx in list\n",
    "\t\t\t\t\t\tmatch_idxs = list(range(match[0],match[1]+1))\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tremove_ids = match_idxs.copy()\n",
    "\t\t\t\t\t\tremove_ids.pop(0)\n",
    "\t\t\t\t\t\tdel lst_temp[remove_ids[0]:remove_ids[-1]]\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# replace annotation @ first mached index\n",
    "\t\t\t\t\t\tlst_temp[match[0]] = express\n",
    "\n",
    "\t\t\t\t\t\tt = \"\".join(lst_temp)\n",
    "\t\t\t\t\t\t\n",
    "#\t\t\t\t\telse:\n",
    "#\t\t\t\t\t\tprint('not found in sentence')\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint('[note] please use (word-tag format)!')\n",
    "\t\t\t\t\t\n",
    "\t\t# finished annotation\n",
    "\t\tldf = pd.concat([self.deactive_df,self.active_df],axis=0)\n",
    "\t\tldf.to_csv('ner_modelparams_annot.csv',index=False)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "#df_annot = pd.read_csv('sentence_splitters.csv')   # read dataframe\n",
    "df_annot = pd.read_csv('ner_modelparams_annot.csv')   # read dataframe\n",
    "\n",
    "temp = ner_annotator(df_annot)  #   start annotating documents\n",
    "#temp.drop_annotations([3,4])   # drop annotations \n",
    "temp.review_annotations()       # show annotated rows        \n",
    "temp.ner_annotate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6cbd337-31a5-4474-bd61-e15e207c8804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'massive_annotator.ipynb',\n",
       " 'bf4.ipynb',\n",
       " 'simple_NER.ipynb',\n",
       " 'ner_modelparams_annot.csv',\n",
       " 'mllibs_setup.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'penguins.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os; os.listdir('../utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f455ba2d-1bba-4d56-8bec-b99e95c7abe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mac/Documents/GitHub/mllibs/utils'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeb49da0-5924-4a2e-82ab-7fb18205a119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>annot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>create label encoding of column B using data A</td>\n",
       "      <td>create label encoding [subset : of column] B [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>create label encoding of column A using data B</td>\n",
       "      <td>create label encoding [subset : of column] A [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>create label encoding using active columns C o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>create one hot encoding of data A using active...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>one hot encoding of data C (set active columns C)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "51     create label encoding of column B using data A   \n",
       "52     create label encoding of column A using data B   \n",
       "53  create label encoding using active columns C o...   \n",
       "54  create one hot encoding of data A using active...   \n",
       "55  one hot encoding of data C (set active columns C)   \n",
       "\n",
       "                                                annot  \n",
       "51  create label encoding [subset : of column] B [...  \n",
       "52  create label encoding [subset : of column] A [...  \n",
       "53                                                NaN  \n",
       "54                                                NaN  \n",
       "55                                                NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annot = pd.read_csv('ner_modelparams_annot.csv')   # read dataframe\n",
    "df_annot.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef79e4-5fc1-402d-8f7e-b4694118baa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f235c-2242-4400-8b85-d9e2fa92c85b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
