{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5719c39a0614e23b05e37f1ff0e8dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_539e4e689f7b422ba6509bd68956529e",
              "IPY_MODEL_84c60ce09fdc4fb0843f910a8b7701b3",
              "IPY_MODEL_c0146be2410f4e03892e6561b39e10ee"
            ],
            "layout": "IPY_MODEL_678e6b59705d468fa96a98ac97a440c5"
          }
        },
        "539e4e689f7b422ba6509bd68956529e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b3999f6cc4047f7899d62c67493a079",
            "placeholder": "​",
            "style": "IPY_MODEL_b56801ece703448fa915430b6c7bd8d3",
            "value": "100%"
          }
        },
        "84c60ce09fdc4fb0843f910a8b7701b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afbab21ba8bf4e48944196b1431dd76a",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9525e131a67946a38672527cc0155fe8",
            "value": 100
          }
        },
        "c0146be2410f4e03892e6561b39e10ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77819234cb4743c3bfc4dc7c9c73e771",
            "placeholder": "​",
            "style": "IPY_MODEL_4bdd4d51ee634ae29896bff5b693e816",
            "value": " 100/100 [01:11&lt;00:00,  1.38it/s]"
          }
        },
        "678e6b59705d468fa96a98ac97a440c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b3999f6cc4047f7899d62c67493a079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56801ece703448fa915430b6c7bd8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afbab21ba8bf4e48944196b1431dd76a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9525e131a67946a38672527cc0155fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77819234cb4743c3bfc4dc7c9c73e771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdd4d51ee634ae29896bff5b693e816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn import preprocessing\n",
        "import requests\n",
        "import io\n",
        "import zipfile\n",
        "\n",
        "'''\n",
        "\n",
        "Training Model\n",
        "\n",
        "# requires gt_corpus.csv\n",
        "# global activation function works quite well atm\n",
        "\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('gt_corpus.csv')\n",
        "classes = len(df['class'].unique())\n",
        "le = preprocessing.LabelEncoder()\n",
        "targets = le.fit_transform(df['task'])\n",
        "data = {'corpus':list(df['text']),'labels':targets}\n",
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YNfdYm31G_J",
        "outputId": "5fc276d4-fdb2-4395-dcb3-6cba7d4e8899"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['corpus', 'labels'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define corpus\n",
        "corpus = df\n",
        "classes = len(corpus['class'].unique())\n",
        "\n",
        "'''\n",
        "\n",
        "Load the base models\n",
        "\n",
        "            & send it to GPU\n",
        "\n",
        "'''\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "model_name = 'prajjwal1/bert-mini'\n",
        "# model_name = 'bert-base-uncased'\n",
        "tokeniser = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yhcaPaZGNPr",
        "outputId": "e6ca89b7-1f01-48f9-cfc1-fb6ea4949ea1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-mini and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "Read Fine-Tuned Classifier Model (in Archived Format)\n",
        "\n",
        "            Load model called in module\n",
        "\n",
        "'''\n",
        "\n",
        "# def download_and_extract_zip(url, extract_path):\n",
        "#     # Send a GET request to the GitHub raw URL to download the ZIP file\n",
        "#     response = requests.get(url)\n",
        "\n",
        "#     # Check if the request was successful\n",
        "#     if response.status_code == 200:\n",
        "#         # Create a file-like object from the downloaded content\n",
        "#         zip_file = io.BytesIO(response.content)\n",
        "\n",
        "#         # Extract the contents of the ZIP file to the specified extract path\n",
        "#         with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "#             zip_ref.extractall(extract_path)\n",
        "#         print(f\"ZIP file extracted to {extract_path}\")\n",
        "#     else:\n",
        "#         print(f\"Failed to download ZIP file from {url}\")\n",
        "\n",
        "# download_and_extract_zip('https://github.com/mllibs/mllibs/raw/main/data/models/bert_classifier_model.zip', 'local_classifier')\n",
        "# model = BertForSequenceClassification.from_pretrained('local_classifier')"
      ],
      "metadata": {
        "id": "uMl9_dMNiYMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Sample dataset for text classification\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        return {'text': text, 'label': label}\n",
        "\n",
        "dataset = CustomDataset(list(data['corpus']),\n",
        "                        list(data['labels']))\n",
        "\n",
        "def train_bert(dataset,tokeniser,model):\n",
        "\n",
        "    # Define batch size and create data loader\n",
        "    batch_size = 10\n",
        "    dataloader = DataLoader(dataset,\n",
        "                            sampler=RandomSampler(dataset),\n",
        "                            batch_size=batch_size)\n",
        "\n",
        "    # Set up optimizer and learning rate scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    total_steps = len(dataloader) * 2\n",
        "\n",
        "    # Train the model\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(100)):\n",
        "        model.train()\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        for batch in dataloader:\n",
        "\n",
        "            inputs = tokeniser(batch['text'], padding=True, truncation=True, return_tensors='pt')\n",
        "            inputs.to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
        "        total_correct += (predicted_labels == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f'Epoch {epoch+1} completed. Accuracy: {accuracy:.4f}')\n",
        "    return model\n",
        "\n",
        "model = train_bert(dataset,tokeniser,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "d5719c39a0614e23b05e37f1ff0e8dd1",
            "539e4e689f7b422ba6509bd68956529e",
            "84c60ce09fdc4fb0843f910a8b7701b3",
            "c0146be2410f4e03892e6561b39e10ee",
            "678e6b59705d468fa96a98ac97a440c5",
            "2b3999f6cc4047f7899d62c67493a079",
            "b56801ece703448fa915430b6c7bd8d3",
            "afbab21ba8bf4e48944196b1431dd76a",
            "9525e131a67946a38672527cc0155fe8",
            "77819234cb4743c3bfc4dc7c9c73e771",
            "4bdd4d51ee634ae29896bff5b693e816"
          ]
        },
        "id": "FAgCRlTx1KME",
        "outputId": "dee70f69-9282-4be4-94e6-80b1a91dec1c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5719c39a0614e23b05e37f1ff0e8dd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 completed. Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = model.to('cpu')\n",
        "model.save_pretrained('bert_classifier_model')"
      ],
      "metadata": {
        "id": "zi0eYZ87qBAz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "Create Archive of Model Folder\n",
        "\n",
        "'''\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "def create_zip_archive(folder_path, zip_file_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n",
        "\n",
        "# Example usage\n",
        "colab_folder_path = \"/content/bert_classifier_model\"  # Replace with the path of your folder in Colab\n",
        "local_save_path = \"bert_classifier_model.zip\"  # Path where you want to save the downloaded ZIP file\n",
        "create_zip_archive(colab_folder_path, local_save_path)\n",
        "print(f\"Folder archived and saved as {local_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1SaK4Qxjknb",
        "outputId": "a605c034-45df-4f03-b29e-69a1b1b3740b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder archived and saved as bert_classifier_model.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "II Inference with Transformer Encoder\n",
        "\n",
        "'''\n",
        "\n",
        "model.to('cpu')\n",
        "\n",
        "def inference(text,tokeniser,model):\n",
        "\n",
        "    # Tokenize the input text\n",
        "    inputs = tokeniser(input_text,\n",
        "                       padding=True,\n",
        "                       truncation=True,\n",
        "                       return_tensors='pt')\n",
        "\n",
        "    # Perform inference using the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Get the predicted label\n",
        "    predicted_label = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # Print the predicted label\n",
        "    print(f\"The predicted label for the input text is: {le.classes_[predicted_label]}\")\n",
        "\n",
        "# fine\n",
        "# input_text = \"I'd like you to create a seaborn scatterplot\" # 61\n",
        "# input_text = \"I want to plot a figure using the seaborn scatter plot\" # 61\n",
        "input_text = \"create plotly count heatmap x: bill_depth_mm y: flipper_length_mm hue: island col: island using penguins\"\n",
        "inference(input_text,tokeniser,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcw_2pIW1Ng2",
        "outputId": "be3675e3-b87b-4b72-acb2-f2343f9589a7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted label for the input text is: sheatmap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# incorrect\n",
        "input_text = \"I'd like you to create a scatterplot using plotly set parameters as x: bill_depth_mm y: flipper_length_mm hue: island col: island using penguins\"\n",
        "inference(input_text,tokeniser,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrU6kE19k3E-",
        "outputId": "255435a8-ff4a-435f-cc42-77c8cfa00ebd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted label for the input text is: col_scatter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# incorrect\n",
        "input_text = \"create a scatter plot using plotly set parameters as x: bill_depth_mm y: flipper_length_mm hue: island col: island using penguins\"\n",
        "inference(input_text,tokeniser,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEAo851Rk9Dg",
        "outputId": "81c379fe-8016-4c08-ba39-4cd73db50463"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted label for the input text is: col_scatter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction of parameters only (which works well with QA) improves accuracy\n",
        "input_text = \"create a scatter plot using plotly using penguins\"\n",
        "inference(input_text,tokeniser,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxytJBJg7PXk",
        "outputId": "5baf4986-e18e-42b2-916b-38abba9a79b7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted label for the input text is: plscatter\n"
          ]
        }
      ]
    }
  ]
}